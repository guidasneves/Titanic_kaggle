{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%pylab inline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leitura e Tratamento dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./dataset/train.csv')\n",
    "test = pd.read_csv('./dataset/test.csv')\n",
    "print(f'Train set shape: {train.shape}\\nTest set shape: {test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Embarked'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Sex'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Sex_b'] = train['Sex'].map(lambda x: 1 if x == 'female' else 0)\n",
    "test['Sex_b'] = test['Sex'].map(lambda x: 1 if x == 'female' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Sex_b'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list(train['Cabin'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Embarked_S'] = (train['Embarked'] == 'S').astype(int)\n",
    "train['Embarked_C'] = (train['Embarked'] == 'C').astype(int)\n",
    "\n",
    "train['Cabin_null'] = train['Cabin'].isnull().astype(int)\n",
    "train['Cabin_C'] = train['Cabin'].fillna('').str.contains('C').astype(int)\n",
    "train['Cabin_E'] = train['Cabin'].fillna('').str.contains('E').astype(int)\n",
    "train['Cabin_G'] = train['Cabin'].fillna('').str.contains('G').astype(int)\n",
    "train['Cabin_D'] = train['Cabin'].fillna('').str.contains('D').astype(int)\n",
    "train['Cabin_A'] = train['Cabin'].fillna('').str.contains('A').astype(int)\n",
    "train['Cabin_B'] = train['Cabin'].fillna('').str.contains('B').astype(int)\n",
    "train['Cabin_F'] = train['Cabin'].fillna('').str.contains('F').astype(int)\n",
    "train['Cabin_T'] = train['Cabin'].fillna('').str.contains('T').astype(int)\n",
    "\n",
    "train['Name_Miss'] = train['Name'].str.contains('Miss.').astype(int)\n",
    "train['Name_Mrs'] = train['Name'].str.contains('Mrs.').astype(int)\n",
    "train['Name_Master'] = train['Name'].str.contains('Master.').astype(int)\n",
    "train['Name_Col'] = train['Name'].str.contains('Col.').astype(int)\n",
    "train['Name_Major'] = train['Name'].str.contains('Major.').astype(int)\n",
    "train['Name_Mr'] = train['Name'].str.contains('Mr.').astype(int)\n",
    "train['Name_Dr'] = train['Name'].str.contains('Dr.').astype(int)\n",
    "train['Name_Don'] = train['Name'].str.contains('Don.').astype(int)\n",
    "train['Name_Sir'] = train['Name'].str.contains('Sir.').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Embarked_S'] = (test['Embarked'] == 'S').astype(int)\n",
    "test['Embarked_C'] = (test['Embarked'] == 'C').astype(int)\n",
    "\n",
    "#test['Cabin_null'] = test['Cabin'].map(lambda x: 0 if x is np.nan else len(str(x)))\n",
    "test['Cabin_null'] = test['Cabin'].isnull().astype(int)\n",
    "test['Cabin_C'] = test['Cabin'].fillna('').str.contains('C').astype(int)\n",
    "test['Cabin_E'] = test['Cabin'].fillna('').str.contains('E').astype(int)\n",
    "test['Cabin_G'] = test['Cabin'].fillna('').str.contains('G').astype(int)\n",
    "test['Cabin_D'] = test['Cabin'].fillna('').str.contains('D').astype(int)\n",
    "test['Cabin_A'] = test['Cabin'].fillna('').str.contains('A').astype(int)\n",
    "test['Cabin_B'] = test['Cabin'].fillna('').str.contains('B').astype(int)\n",
    "test['Cabin_F'] = test['Cabin'].fillna('').str.contains('F').astype(int)\n",
    "test['Cabin_T'] = test['Cabin'].fillna('').str.contains('T').astype(int)\n",
    "\n",
    "test['Name_Miss'] = test['Name'].str.contains('Miss.').astype(int)\n",
    "test['Name_Mrs'] = test['Name'].str.contains('Mrs.').astype(int)\n",
    "test['Name_Master'] = test['Name'].str.contains('Master.').astype(int)\n",
    "test['Name_Col'] = test['Name'].str.contains('Col.').astype(int)\n",
    "test['Name_Major'] = test['Name'].str.contains('Major.').astype(int)\n",
    "test['Name_Mr'] = test['Name'].str.contains('Mr.').astype(int)\n",
    "test['Name_Dr'] = test['Name'].str.contains('Dr.').astype(int)\n",
    "test['Name_Don'] = test['Name'].str.contains('Don.').astype(int)\n",
    "test['Name_Sir'] = test['Name'].str.contains('Sir.').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variaveis = ['Sex_b', 'Age', 'Pclass', 'Embarked_S', 'Embarked_C', 'SibSp', 'Parch', 'Fare', 'Cabin_null',\n",
    "             'Cabin_C', 'Cabin_E', 'Cabin_G', 'Cabin_D', 'Cabin_A', 'Cabin_B', 'Cabin_F', 'Cabin_T',\n",
    "             'Name_Miss', 'Name_Mrs', 'Name_Master', 'Name_Col', 'Name_Major', 'Name_Mr', 'Name_Dr', 'Name_Don', 'Name_Sir']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train[variaveis].fillna(-1)\n",
    "X_test = test[variaveis].fillna(-1)\n",
    "y = train['Survived']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressão Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = RepeatedKFold(n_splits=3, n_repeats=10, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "step_train = []\n",
    "step = []\n",
    "\n",
    "for linhas_train, linhas_cv in kf.split(X):\n",
    "    X_train, X_cv = X.iloc[linhas_train].copy(), X.iloc[linhas_cv].copy()\n",
    "    y_train, y_cv = y.iloc[linhas_train].copy(), y.iloc[linhas_cv].copy()\n",
    "\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_cv = scaler.transform(X_cv)\n",
    "\n",
    "    model = LogisticRegression(penalty='l2', random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    yhat_train = model.predict(X_train)\n",
    "    yhat = model.predict(X_cv)\n",
    "\n",
    "    acc_train = np.mean(y_train == yhat_train)\n",
    "    acc = np.mean(y_cv == yhat)\n",
    "    print(f'acc_train: {acc_train}, acc_cv: {acc}\\n')\n",
    "\n",
    "    step_train.append(acc_train)\n",
    "    step.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Train mean: {np.mean(step_train)}, CV mean: {np.mean(step)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pylab.hist(step), pylab.hist(step_train, alpha=.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise de Erro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cv_erro = train.iloc[linhas_cv].copy()\n",
    "X_cv_erro['yhat'] = yhat\n",
    "X_cv_erro.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "erro = X_cv_erro[X_cv_erro['Survived'] != X_cv_erro['yhat']]\n",
    "erro = erro[['PassengerId', 'Survived', 'yhat', 'Name', 'Sex', 'Sex_b', 'Embarked', 'Age', 'Ticket', 'Cabin', 'Cabin_null', 'Pclass', 'Embarked_S', 'Embarked_C', 'SibSp', 'Parch', 'Fare', 'Cabin_null',\n",
    "             'Name_Miss', 'Name_Mrs', 'Name_Master', 'Name_Col', 'Name_Major', 'Name_Mr', 'Name_Dr', 'Name_Don', 'Name_Sir']]\n",
    "erro.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "female = erro[erro['Sex_b'] == 1]\n",
    "male = erro[erro['Sex_b'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "female.sort_values('Survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "male.sort_values('Survived')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retreinando o Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = scaler.fit_transform(X)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(penalty='l2', random_state=42)\n",
    "model.fit(X, y)\n",
    "\n",
    "y_hat = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criando o Resultado das Previsões para Importar ao Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.Series(y_hat, index=test['PassengerId'], name='Survived')\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_t.to_csv('./yhat/logistic_regression.csv', header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
