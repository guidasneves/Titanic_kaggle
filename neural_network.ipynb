{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "np.set_printoptions(precision=2)\n",
    "import logging\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "tf.autograph.set_verbosity(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leitura e Tratamento dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./dataset/train.csv')\n",
    "test = pd.read_csv('./dataset/test.csv')\n",
    "display(train)\n",
    "display(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Train set shape: {train.shape}\\nTest set shape: {test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Embarked'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transforma_embarked(feature):\n",
    "    if feature == 'S':\n",
    "        return 0\n",
    "    elif feature == 'C':\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "\n",
    "train['Embarked_b'] = train['Embarked'].map(transforma_embarked)\n",
    "test['Embarked_b'] = test['Embarked'].map(transforma_embarked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variaveis = ['Sex_b', 'Age', 'Name_t', 'Pclass', 'Embarked_b', 'SibSp', 'Parch', 'Fare']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Sex'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transforma_sexo(feature):\n",
    "    if feature == 'female':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "train['Sex_b'] = train['Sex'].map(transforma_sexo)\n",
    "test['Sex_b'] = test['Sex'].map(transforma_sexo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(train.head())\n",
    "train['Sex_b'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nome = ['Mr.', 'Miss.', 'Mrs.', 'Master.', 'Dr.', 'Col.', 'Major.', 'Sir.', 'Rev.', 'Mlle.', 'Capt.', 'Lady.', 'Nme.', 'Ms.', 'Jonkheer.', 'Don.']\n",
    "def split(feature):\n",
    "    for i in nome:\n",
    "        if i in feature:\n",
    "            return f'{nome.index(i):.0f}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Name_t'] = train['Name'].map(split)\n",
    "test['Name_t'] = test['Name'].map(split)\n",
    "train['Name_t'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[variaveis].fillna(-1)\n",
    "X_test = test[variaveis].fillna(-1)\n",
    "y_train = train['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_s, X_cv, y_train_s, y_cv = train_test_split(X_train, y_train, test_size=0.4, random_state=42)\n",
    "X_train_s.shape, X_cv.shape, y_train_s.shape, y_cv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_norm = scaler.fit_transform(X_train_s)\n",
    "X_train_norm, X_train_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cv_norm = scaler.transform(X_cv)\n",
    "X_test_norm = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rede Neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "lambda_r = 1e-2\n",
    "\n",
    "# Criando o modelo\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(units=250, activation='relu', name='L1', kernel_regularizer=tf.keras.regularizers.l2(lambda_r)),\n",
    "    tf.keras.layers.Dense(units=150, activation='relu', name='L2', kernel_regularizer=tf.keras.regularizers.l2(lambda_r)),\n",
    "    tf.keras.layers.Dense(units=75, activation='relu', name='L3', kernel_regularizer=tf.keras.regularizers.l2(lambda_r)),\n",
    "    tf.keras.layers.Dense(units=25, activation='relu', name='L4', kernel_regularizer=tf.keras.regularizers.l2(lambda_r)),\n",
    "    tf.keras.layers.Dense(units=1, activation='linear', name='L5')\n",
    "], name='model')\n",
    "\n",
    "# Definindo a loss e otimizador\n",
    "model.compile(loss=BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=Adam(learning_rate=learning_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#treinando o modelo\n",
    "model.fit(X_train_norm, y_train_s, epochs=500, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setando o threshold para a classificação\n",
    "threshold = 0.5\n",
    "\n",
    "#gravando a fração de erro dos exemplos para o trainingset\n",
    "yhat = model.predict(X_train_norm)\n",
    "yhat = tf.math.sigmoid(yhat)\n",
    "yhat = np.where(yhat >= threshold, 1, 0)\n",
    "train_error = np.sum(yhat) / np.sum(y_train_s)\n",
    "\n",
    "#gravando a fração de erro dos exemplos para o cvset\n",
    "yhat = model.predict(X_cv_norm)\n",
    "yhat = tf.math.sigmoid(yhat)\n",
    "yhat = np.where(yhat >= threshold, 1, 0)\n",
    "cv_error = np.sum(yhat) / np.sum(y_cv)\n",
    "\n",
    "# projetando os resultados\n",
    "print(f'Erro do training set: {train_error:.2f}, erro do cv set: {cv_error:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computando a previsão de X_test\n",
    "yhat = model.predict(X_test_norm)\n",
    "yhat = tf.math.sigmoid(yhat)\n",
    "yhat = np.where(yhat >=threshold, 1, 0)\n",
    "yhat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criando o Resultado das Previsões para Importar ao Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.Series(yhat.reshape(-1), index=test['PassengerId'], name='Survived')\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('./yhat/neural_network_model.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
